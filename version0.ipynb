{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4712,"sourceType":"datasetVersion","datasetId":2749}],"dockerImageVersionId":30587,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport librosa \nimport tensorflow as tf\nimport librosa.display\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nimport tensorflow.keras.layers as layers\nfrom sklearn.metrics import confusion_matrix,classification_report,accuracy_score,f1_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-30T17:41:34.058790Z","iopub.execute_input":"2023-11-30T17:41:34.059909Z","iopub.status.idle":"2023-11-30T17:41:34.066013Z","shell.execute_reply.started":"2023-11-30T17:41:34.059869Z","shell.execute_reply":"2023-11-30T17:41:34.065071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import Audio\nimport torchaudio, torchvision\nimport scipy.io.wavfile as sci_wav  # Open wav files","metadata":{"execution":{"iopub.status.busy":"2023-11-30T17:32:14.188698Z","iopub.execute_input":"2023-11-30T17:32:14.189184Z","iopub.status.idle":"2023-11-30T17:32:14.261311Z","shell.execute_reply.started":"2023-11-30T17:32:14.189151Z","shell.execute_reply":"2023-11-30T17:32:14.259547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Audio Visualizations","metadata":{}},{"cell_type":"code","source":"def plot_audio(path):\n    waveform, sample_rate = torchaudio.load(path)\n\n    print(\"Shape of waveform: {}\".format(waveform.size()))\n    print(\"Sample rate of waveform: {}\".format(sample_rate))\n\n    plt.figure()\n    plt.plot(waveform.t().numpy())\n    plt.show()\n    Audio(waveform.numpy(), rate=sample_rate)\n    return waveform, sample_rate","metadata":{"execution":{"iopub.status.busy":"2023-11-30T17:14:37.779049Z","iopub.execute_input":"2023-11-30T17:14:37.779726Z","iopub.status.idle":"2023-11-30T17:14:37.788411Z","shell.execute_reply.started":"2023-11-30T17:14:37.779685Z","shell.execute_reply":"2023-11-30T17:14:37.786585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_spectrogram(path):\n    waveform, sample_rate = torchaudio.load(path)\n    spectrogram = torchaudio.transforms.Spectrogram()(waveform)\n    print(\"\\nShape of spectrogram: {}\".format(spectrogram.size()))\n\n    plt.figure(figsize = (12, 6))\n    plt.imshow(\n        spectrogram.log2()[0, :, :].numpy(), \n        cmap='gray', \n        vmin = -40, \n        vmax = 15\n    )\n    plt.title(\"Spectrogram\")\n    plt.xlabel('Time')\n    plt.ylabel('Frequency bins')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T17:18:02.153223Z","iopub.execute_input":"2023-11-30T17:18:02.153730Z","iopub.status.idle":"2023-11-30T17:18:02.163700Z","shell.execute_reply.started":"2023-11-30T17:18:02.153689Z","shell.execute_reply":"2023-11-30T17:18:02.161906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '/kaggle/input/audio-cats-and-dogs/cats_dogs/train/cat/cat_54.wav'\nplot_audio(path = path)\nshow_spectrogram(path = path)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T17:19:10.465754Z","iopub.execute_input":"2023-11-30T17:19:10.466269Z","iopub.status.idle":"2023-11-30T17:19:11.416371Z","shell.execute_reply.started":"2023-11-30T17:19:10.466235Z","shell.execute_reply":"2023-11-30T17:19:11.415173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '/kaggle/input/audio-cats-and-dogs/cats_dogs/train/dog/dog_barking_30.wav'\nplot_audio(path = path)\nshow_spectrogram(path = path)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T17:19:30.597634Z","iopub.execute_input":"2023-11-30T17:19:30.598051Z","iopub.status.idle":"2023-11-30T17:19:31.591813Z","shell.execute_reply.started":"2023-11-30T17:19:30.598020Z","shell.execute_reply":"2023-11-30T17:19:31.590157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Prepare data**","metadata":{}},{"cell_type":"code","source":"# List the wav files\nROOT_DIR = '/kaggle/input/audio-cats-and-dogs/cats_dogs/'\nX_path = os.listdir(ROOT_DIR)\ny = [0 if 'cat' in f else 1 for f in X_path]  # change y to int values\n\n# Split train and test\nX_train, X_test, y_train, y_test = train_test_split(X_path, y, test_size=0.33)\n\nprint(\"in X, there is {} cats and {} dogs\".format(len(y) - sum(y), sum(y)))\nprint(\"in X_train, there is {} cats and {} dogs\".format(len(y_train) - sum(y_train), sum(y_train)))\nprint(\"in X_test, there is {} cats and {} dogs\".format(len(y_test) - sum(y_test), sum(y_test)))","metadata":{"execution":{"iopub.status.busy":"2023-11-30T17:33:29.854246Z","iopub.execute_input":"2023-11-30T17:33:29.854693Z","iopub.status.idle":"2023-11-30T17:33:29.865853Z","shell.execute_reply.started":"2023-11-30T17:33:29.854664Z","shell.execute_reply":"2023-11-30T17:33:29.864801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport scipy.io.wavfile as sci_wav\n\nROOT_DIR = '/kaggle/input/audio-cats-and-dogs/cats_dogs/'\n\ndef read_wav_files(wav_files):\n    '''Returns a list of audio waves\n    Params:\n        wav_files: List of .wav paths\n    \n    Returns:\n        List of audio signals\n    '''\n    if not isinstance(wav_files, list):\n        wav_files = [wav_files]\n    \n    audio_signals = []\n    for f in wav_files:\n        # Check if the path is a directory\n        if os.path.isdir(ROOT_DIR + f):\n            # If it's a directory, get all .wav files in the directory\n            wav_files_in_dir = [os.path.join(ROOT_DIR + f, wav) for wav in os.listdir(ROOT_DIR + f) if wav.endswith('.wav')]\n            # Read each .wav file in the directory\n            audio_signals.extend([sci_wav.read(wav)[1] for wav in wav_files_in_dir])\n        else:\n            # If it's a file, read the single .wav file\n            audio_signals.append(sci_wav.read(ROOT_DIR + f)[1])\n    \n    return audio_signals\n\n# Example usage\nprint(read_wav_files('cat_1.wav'))\nprint(read_wav_files(['cat_1.wav', 'cat_2.wav']))\n\n# Assuming X_train and X_test are lists of file paths or directories\nX_train, X_test = map(read_wav_files, [X_train, X_test])\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T17:38:38.136379Z","iopub.execute_input":"2023-11-30T17:38:38.136822Z","iopub.status.idle":"2023-11-30T17:38:39.712553Z","shell.execute_reply.started":"2023-11-30T17:38:38.136790Z","shell.execute_reply":"2023-11-30T17:38:39.711170Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_all = read_wav_files(X_path)\nX_all_cat = [_x for _x, _y in zip(X_all, y) if _y == 0]\nX_all_dog = [_x for _x, _y in zip(X_all, y) if _y == 1]\nX_all_cat = np.concatenate(X_all_cat)\nX_all_dog = np.concatenate(X_all_dog)\n\nprint('Overall, there is {:.2f} sec of cats and {:.2f} sec of dogs'.format(\n    len(X_all_cat) / 16000, len(X_all_dog) / 16000))","metadata":{"execution":{"iopub.status.busy":"2023-11-30T17:39:52.663790Z","iopub.execute_input":"2023-11-30T17:39:52.664369Z","iopub.status.idle":"2023-11-30T17:39:53.118808Z","shell.execute_reply.started":"2023-11-30T17:39:52.664318Z","shell.execute_reply":"2023-11-30T17:39:53.117390Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# THE MODELING","metadata":{}},{"cell_type":"markdown","source":"Generate what'll be the official train/test split\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport random\n\n# Randomize cat and dog file paths\ncat_paths = [_x for _x, _y in zip(X_path, y) if _y == 0]\ndog_paths = [_x for _x, _y in zip(X_path, y) if _y == 1]\nrandom.shuffle(cat_paths)\nrandom.shuffle(dog_paths)\n\nn = int(len(cat_paths) * .3)\n\nsplits = {\n    'train_cat': cat_paths[n:],\n    'train_dog': dog_paths[n:],\n    'test_cat': cat_paths[:n],\n    'test_dog': dog_paths[:n]\n}\ndf = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in splits.items() ]))\ndf.to_csv('train_test_split.csv')","metadata":{"execution":{"iopub.status.busy":"2023-11-30T17:40:14.395341Z","iopub.execute_input":"2023-11-30T17:40:14.395769Z","iopub.status.idle":"2023-11-30T17:40:14.418923Z","shell.execute_reply.started":"2023-11-30T17:40:14.395737Z","shell.execute_reply":"2023-11-30T17:40:14.417223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plot the raw audio wave","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfig, axs = plt.subplots(2, 2, figsize=(16,7))\naxs[0][0].plot(X_train[0])\naxs[0][1].plot(X_train[1])\naxs[1][0].plot(X_train[2])\naxs[1][1].plot(X_train[3])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T17:40:27.639479Z","iopub.execute_input":"2023-11-30T17:40:27.639895Z","iopub.status.idle":"2023-11-30T17:40:29.334992Z","shell.execute_reply.started":"2023-11-30T17:40:27.639866Z","shell.execute_reply":"2023-11-30T17:40:29.333270Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cats_and_dogs_gen(dataset='train', n_samples=20, sample_len=16000):\n    '''This generator is going to return batchs of size <n_sample>*<sample_len>\n    \n    Params:\n        dataset: Either 'train' or 'test', to choose in between them\n        n_samples: amount of samples per batch\n        sample_len: size of the samples in a batch\n    '''\n    # Select between train or test\n    X, y = (X_train, y_train) if dataset == 'train' else (X_test, y_test)\n    \n    # Create two huuuges 1D arrays with all the audio waves concatenated one after the other\n    # (one for the cats, the other for the dogs)\n    X_cat = np.concatenate([_x for _x, _y in zip(X, y) if _y == 0])\n    X_dog = np.concatenate([_x for _x, _y in zip(X, y) if _y == 1])\n    \n    # Apply normalization and mean suppression\n    X_cat = preprocessing.scale(X_cat)\n    X_dog = preprocessing.scale(X_dog)\n    \n    for _ in range(int(max(sum(y), len(y) - sum(y)) / n_samples)):\n        y_batch = np.zeros(n_samples)\n        X_batch = np.zeros((n_samples, sample_len))\n        for idx in range(n_samples):\n            y_batch[idx] = idx % 2\n            _X = X_cat if y_batch[idx] == 0 else X_dog\n            x_idx = np.random.randint(len(_X) - sample_len)\n            X_batch[idx] = _X[x_idx : x_idx + sample_len]\n        \n        yield (X_batch.reshape(n_samples, sample_len, 1),\n               y_batch.reshape(-1, 1) )\n        \n# Test the generator here\nx, y = next(cats_and_dogs_gen('train'))\nprint(x.shape, y.shape)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T17:42:44.644408Z","iopub.execute_input":"2023-11-30T17:42:44.644840Z","iopub.status.idle":"2023-11-30T17:42:45.323990Z","shell.execute_reply.started":"2023-11-30T17:42:44.644810Z","shell.execute_reply":"2023-11-30T17:42:45.322835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"the model:\n","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom collections import namedtuple\n\ndef build_neural_network():\n    inputs = tf.keras.Input(shape=(None, 1))\n    labels = tf.keras.Input(shape=(1,))\n    learning_rate = tf.keras.Input(shape=(), dtype=tf.float32)\n    is_training = tf.Variable(True, dtype=tf.bool)\n\n    nn = tf.keras.layers.Conv1D(filters=10, kernel_size=3, strides=2, activation=tf.nn.relu)(inputs)\n    \n    for _ in range(9):\n        nn = tf.keras.layers.Conv1D(filters=10, kernel_size=3, strides=2, activation=tf.nn.relu)(nn)\n        nn = tf.keras.layers.BatchNormalization()(nn, training=is_training)\n\n    # Global average pooling\n    nn = tf.reduce_mean(nn, axis=1)\n\n    logits = tf.keras.layers.Dense(1, activation=None)(nn)\n    cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=labels, logits=logits)\n    cost = tf.reduce_mean(cross_entropy)\n\n    with tf.control_dependencies(tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.UPDATE_OPS)):\n        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n        train_op = optimizer.minimize(cost)\n\n    predicted = tf.nn.sigmoid(logits)\n    correct_pred = tf.equal(tf.round(predicted), labels)\n    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n    # Export the nodes \n    export_nodes = ['inputs', 'labels', 'learning_rate', 'is_training', 'logits',\n                    'cost', 'train_op', 'predicted', 'accuracy']\n    Graph = namedtuple('Graph', export_nodes)\n    local_dict = locals()\n    graph = Graph(*[local_dict[each] for each in export_nodes])\n\n    return graph\n\nmodel = build_neural_network()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T17:47:12.565269Z","iopub.execute_input":"2023-11-30T17:47:12.565997Z","iopub.status.idle":"2023-11-30T17:47:14.808656Z","shell.execute_reply.started":"2023-11-30T17:47:12.565939Z","shell.execute_reply":"2023-11-30T17:47:14.805892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 100\ntrain_collect = 2\ntrain_print = train_collect * 2\n\nlearning_rate_value = 0.01\n\nx_collect = []\ntrain_loss_collect = []\ntrain_acc_collect = []\nvalid_loss_collect = []\nvalid_acc_collect = []\n\nsaver = tf.train.Saver()\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    iteration=0\n    for e in range(epochs):\n        \n        # Train\n        epoch_loss = []\n        epoch_acc = []\n        for batch_x, batch_y in cats_and_dogs_gen('train'):\n            feed = {model.inputs: batch_x,\n                    model.labels: batch_y,\n                    model.learning_rate: learning_rate_value,\n                    model.is_training:True\n                   }\n            # Do the training\n            batch_loss, _, batch_acc = sess.run([model.cost, model.optimizer, model.accuracy],\n                                                feed_dict=feed)\n            \n            # Accumulate the resulting values\n            epoch_loss.append(batch_loss)\n            epoch_acc.append(batch_acc)\n        \n        # Collect epoch losses and accuracies\n        x_collect.append(e)\n        train_loss_collect.append(np.array(epoch_loss).mean())\n        train_acc_collect.append(np.array(epoch_acc).mean())\n\n        print(\"Epoch: {}/{}\".format(e + 1, epochs),\n              \"Train Loss: {:.4f}\".format(np.array(epoch_loss).mean()),\n              \"Train Acc: {:.4f}\".format(np.array(epoch_acc).mean()))\n        \n        # Validation output\n        epoch_loss = []\n        epoch_acc = []\n        for batch_x, batch_y in cats_and_dogs_gen('test'):\n            feed = {model.inputs: batch_x,\n                    model.labels: batch_y,\n                    model.learning_rate: learning_rate_value,\n                    model.is_training:True\n                   }\n            # Do the training\n            batch_loss, _, batch_acc = sess.run([model.cost, model.optimizer, model.accuracy],\n                                                feed_dict=feed)\n            \n            # Accumulate the resulting values\n            epoch_loss.append(batch_loss)\n            epoch_acc.append(batch_acc)\n            \n        # Collect epoch losses and accuracies\n        valid_loss_collect.append(np.array(epoch_loss).mean())\n        valid_acc_collect.append(np.array(epoch_acc).mean())\n\n    saver.save(sess, \"./cats_dogs.ckpt\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(1, 2, figsize=(15,7))\naxs[0].plot(x_collect, train_loss_collect, \"r--\")\naxs[0].plot(x_collect, valid_loss_collect, \"g--\")\naxs[0].set_title('Loss')\naxs[1].plot(x_collect, train_acc_collect, \"r--\")\naxs[1].plot(x_collect, valid_acc_collect, \"g--\")\naxs[1].set_title('Accuracy')\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}